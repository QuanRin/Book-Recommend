{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ../../requirement.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import string\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>248957</td>\n",
       "      <td>10527</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "      <td>european</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>248957</td>\n",
       "      <td>6843</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>south_asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>248957</td>\n",
       "      <td>3650</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>celtic_english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>248957</td>\n",
       "      <td>11592</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>Male</td>\n",
       "      <td>celtic_english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>248957</td>\n",
       "      <td>1205</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>celtic_english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200117</th>\n",
       "      <td>200117</td>\n",
       "      <td>250730</td>\n",
       "      <td>8627</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Female</td>\n",
       "      <td>east_asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200118</th>\n",
       "      <td>200118</td>\n",
       "      <td>250730</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>east_asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200119</th>\n",
       "      <td>200119</td>\n",
       "      <td>250730</td>\n",
       "      <td>9117</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>east_asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200120</th>\n",
       "      <td>200120</td>\n",
       "      <td>250730</td>\n",
       "      <td>10149</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>Female</td>\n",
       "      <td>celtic_english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200121</th>\n",
       "      <td>200121</td>\n",
       "      <td>250730</td>\n",
       "      <td>5601</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>south_asian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating_id  book_id  user_id  rating  age  gender            area\n",
       "0               0   248957    10527       5   39    Male        european\n",
       "1               1   248957     6843       5   35    Male     south_asian\n",
       "2               2   248957     3650       5   58    Male  celtic_english\n",
       "3               3   248957    11592       5   51    Male  celtic_english\n",
       "4               4   248957     1205       5   60  Female  celtic_english\n",
       "...           ...      ...      ...     ...  ...     ...             ...\n",
       "200117     200117   250730     8627       5   39  Female      east_asian\n",
       "200118     200118   250730       44       5   33    Male      east_asian\n",
       "200119     200119   250730     9117       5   19  Female      east_asian\n",
       "200120     200120   250730    10149       5   53  Female  celtic_english\n",
       "200121     200121   250730     5601       5   31    Male     south_asian\n",
       "\n",
       "[200122 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:/Tài liệu môn học/Đồ án/pbl7/modelAI/ModelAI/data/book_user_ratings_include_user_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns = ['id', 'title', 'description', 'book_cover', 'image_url', 'release_date', 'publisher', 'number_of_pages', 'price', 'authors', 'rating', 'number_of_ratings', 'number_of_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng LabelEncoder từ thư viện scikit-learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Khởi tạo LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Mã hóa cột 'area' thành dạng số\n",
    "df['gender_encoded'] = label_encoder.fit_transform(df['gender'])\n",
    "df['area_encoded'] = label_encoder.fit_transform(df['area'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>area</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>area_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>248957</td>\n",
       "      <td>10527</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "      <td>european</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>248957</td>\n",
       "      <td>6843</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>south_asian</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>248957</td>\n",
       "      <td>3650</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>celtic_english</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>248957</td>\n",
       "      <td>11592</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>Male</td>\n",
       "      <td>celtic_english</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>248957</td>\n",
       "      <td>1205</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>celtic_english</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200117</th>\n",
       "      <td>200117</td>\n",
       "      <td>250730</td>\n",
       "      <td>8627</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>Female</td>\n",
       "      <td>east_asian</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200118</th>\n",
       "      <td>200118</td>\n",
       "      <td>250730</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>east_asian</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200119</th>\n",
       "      <td>200119</td>\n",
       "      <td>250730</td>\n",
       "      <td>9117</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>east_asian</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200120</th>\n",
       "      <td>200120</td>\n",
       "      <td>250730</td>\n",
       "      <td>10149</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>Female</td>\n",
       "      <td>celtic_english</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200121</th>\n",
       "      <td>200121</td>\n",
       "      <td>250730</td>\n",
       "      <td>5601</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>south_asian</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200122 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating_id  book_id  user_id  rating  age  gender            area  \\\n",
       "0               0   248957    10527       5   39    Male        european   \n",
       "1               1   248957     6843       5   35    Male     south_asian   \n",
       "2               2   248957     3650       5   58    Male  celtic_english   \n",
       "3               3   248957    11592       5   51    Male  celtic_english   \n",
       "4               4   248957     1205       5   60  Female  celtic_english   \n",
       "...           ...      ...      ...     ...  ...     ...             ...   \n",
       "200117     200117   250730     8627       5   39  Female      east_asian   \n",
       "200118     200118   250730       44       5   33    Male      east_asian   \n",
       "200119     200119   250730     9117       5   19  Female      east_asian   \n",
       "200120     200120   250730    10149       5   53  Female  celtic_english   \n",
       "200121     200121   250730     5601       5   31    Male     south_asian   \n",
       "\n",
       "        gender_encoded  area_encoded  \n",
       "0                    1             3  \n",
       "1                    1             9  \n",
       "2                    1             1  \n",
       "3                    1             1  \n",
       "4                    0             1  \n",
       "...                ...           ...  \n",
       "200117               0             2  \n",
       "200118               1             2  \n",
       "200119               0             2  \n",
       "200120               0             1  \n",
       "200121               1             9  \n",
       "\n",
       "[200122 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>book_cover</th>\n",
       "      <th>image_url</th>\n",
       "      <th>release_date</th>\n",
       "      <th>publisher</th>\n",
       "      <th>number_of_pages</th>\n",
       "      <th>price</th>\n",
       "      <th>authors</th>\n",
       "      <th>rating</th>\n",
       "      <th>number_of_ratings</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18599856</td>\n",
       "      <td>Where the Crawdads Sing</td>\n",
       "      <td>major motion picture 1 new york time bestselli...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>https://i.thriftbooks.com/api/imagehandler/m/4...</td>\n",
       "      <td>0001-01-01T00:00:00</td>\n",
       "      <td>Corsair</td>\n",
       "      <td>303</td>\n",
       "      <td>14.39</td>\n",
       "      <td>Delia Owens</td>\n",
       "      <td>3.897698</td>\n",
       "      <td>391</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>248957</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone</td>\n",
       "      <td>beloved first book harry potter series fully i...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>https://i.thriftbooks.com/api/imagehandler/m/9...</td>\n",
       "      <td>1998-09-01T00:00:00</td>\n",
       "      <td>Arthur A. Levine Books</td>\n",
       "      <td>320</td>\n",
       "      <td>4.29</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>3.405858</td>\n",
       "      <td>239</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>247716</td>\n",
       "      <td>Nineteen Eighty-Four</td>\n",
       "      <td>written 75 year ago 1984 george orwell chillin...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>https://i.thriftbooks.com/api/imagehandler/m/0...</td>\n",
       "      <td>0001-01-01T00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>187.89</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>3.695279</td>\n",
       "      <td>233</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>248147</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>voted america best loved novel pb great americ...</td>\n",
       "      <td>Mass Market Paperback</td>\n",
       "      <td>https://img.thriftbooks.com/api/images/m/8594c...</td>\n",
       "      <td>1988-10-11T00:00:00</td>\n",
       "      <td>Grand Central Publishing</td>\n",
       "      <td>288</td>\n",
       "      <td>4.19</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>3.548387</td>\n",
       "      <td>186</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>246270</td>\n",
       "      <td>The Alchemist</td>\n",
       "      <td>international bestseller 80 million copy sold ...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>https://i.thriftbooks.com/api/imagehandler/m/1...</td>\n",
       "      <td>1993-04-25T00:00:00</td>\n",
       "      <td>HarperOne</td>\n",
       "      <td>197</td>\n",
       "      <td>5.49</td>\n",
       "      <td>Paulo Coelho</td>\n",
       "      <td>4.002950</td>\n",
       "      <td>339</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10045</th>\n",
       "      <td>10045</td>\n",
       "      <td>13866451</td>\n",
       "      <td>The State of Affairs: Rethinking Infidelity</td>\n",
       "      <td>fresh look infidelity broadening focus havoc w...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>https://i.thriftbooks.com/api/imagehandler/m/B...</td>\n",
       "      <td>2018-10-09T00:00:00</td>\n",
       "      <td>Harper Paperbacks</td>\n",
       "      <td>352</td>\n",
       "      <td>10.49</td>\n",
       "      <td>Esther Perel</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10046</th>\n",
       "      <td>10046</td>\n",
       "      <td>245996</td>\n",
       "      <td>Your Four-Year-Old: Wild and Wonderful</td>\n",
       "      <td>four year old make lovable problem four year o...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41XFP1mCqL...</td>\n",
       "      <td>1980-09-15T00:00:00</td>\n",
       "      <td>Delta</td>\n",
       "      <td>160</td>\n",
       "      <td>6.99</td>\n",
       "      <td>Louise Bates Ames,Frances L. Ilg</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10047</th>\n",
       "      <td>10047</td>\n",
       "      <td>376019</td>\n",
       "      <td>A Hunger for God: Desiring God through Fasting...</td>\n",
       "      <td>encourage read book asking great thing god. da...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>https://i.thriftbooks.com/api/imagehandler/m/4...</td>\n",
       "      <td>2013-04-30T00:00:00</td>\n",
       "      <td>Crossway</td>\n",
       "      <td>208</td>\n",
       "      <td>11.99</td>\n",
       "      <td>John Piper</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10048</th>\n",
       "      <td>10048</td>\n",
       "      <td>1000028213</td>\n",
       "      <td>Casablanca (1942)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DVD</td>\n",
       "      <td>https://img.thriftbooks.com/api/images/e/m/43B...</td>\n",
       "      <td>2002-03-07T00:00:00</td>\n",
       "      <td>Warner Home Video</td>\n",
       "      <td>0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10049</th>\n",
       "      <td>10049</td>\n",
       "      <td>250730</td>\n",
       "      <td>Exploring Creation With Physical Science</td>\n",
       "      <td>course designed last science course student ta...</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>https://i.thriftbooks.com/api/imagehandler/m/C...</td>\n",
       "      <td>2000-01-01T00:00:00</td>\n",
       "      <td>Veritas Pr Inc</td>\n",
       "      <td>445</td>\n",
       "      <td>6.39</td>\n",
       "      <td>Jay L. Wile</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10050 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          id  \\\n",
       "0               0    18599856   \n",
       "1               1      248957   \n",
       "2               2      247716   \n",
       "3               3      248147   \n",
       "4               4      246270   \n",
       "...           ...         ...   \n",
       "10045       10045    13866451   \n",
       "10046       10046      245996   \n",
       "10047       10047      376019   \n",
       "10048       10048  1000028213   \n",
       "10049       10049      250730   \n",
       "\n",
       "                                                   title  \\\n",
       "0                                Where the Crawdads Sing   \n",
       "1                  Harry Potter and the Sorcerer's Stone   \n",
       "2                                   Nineteen Eighty-Four   \n",
       "3                                  To Kill a Mockingbird   \n",
       "4                                          The Alchemist   \n",
       "...                                                  ...   \n",
       "10045        The State of Affairs: Rethinking Infidelity   \n",
       "10046             Your Four-Year-Old: Wild and Wonderful   \n",
       "10047  A Hunger for God: Desiring God through Fasting...   \n",
       "10048                                  Casablanca (1942)   \n",
       "10049           Exploring Creation With Physical Science   \n",
       "\n",
       "                                             description  \\\n",
       "0      major motion picture 1 new york time bestselli...   \n",
       "1      beloved first book harry potter series fully i...   \n",
       "2      written 75 year ago 1984 george orwell chillin...   \n",
       "3      voted america best loved novel pb great americ...   \n",
       "4      international bestseller 80 million copy sold ...   \n",
       "...                                                  ...   \n",
       "10045  fresh look infidelity broadening focus havoc w...   \n",
       "10046  four year old make lovable problem four year o...   \n",
       "10047  encourage read book asking great thing god. da...   \n",
       "10048                                                NaN   \n",
       "10049  course designed last science course student ta...   \n",
       "\n",
       "                  book_cover  \\\n",
       "0                  Paperback   \n",
       "1                  Paperback   \n",
       "2                  Paperback   \n",
       "3      Mass Market Paperback   \n",
       "4                  Paperback   \n",
       "...                      ...   \n",
       "10045              Paperback   \n",
       "10046              Paperback   \n",
       "10047              Paperback   \n",
       "10048                    DVD   \n",
       "10049              Hardcover   \n",
       "\n",
       "                                               image_url         release_date  \\\n",
       "0      https://i.thriftbooks.com/api/imagehandler/m/4...  0001-01-01T00:00:00   \n",
       "1      https://i.thriftbooks.com/api/imagehandler/m/9...  1998-09-01T00:00:00   \n",
       "2      https://i.thriftbooks.com/api/imagehandler/m/0...  0001-01-01T00:00:00   \n",
       "3      https://img.thriftbooks.com/api/images/m/8594c...  1988-10-11T00:00:00   \n",
       "4      https://i.thriftbooks.com/api/imagehandler/m/1...  1993-04-25T00:00:00   \n",
       "...                                                  ...                  ...   \n",
       "10045  https://i.thriftbooks.com/api/imagehandler/m/B...  2018-10-09T00:00:00   \n",
       "10046  https://m.media-amazon.com/images/I/41XFP1mCqL...  1980-09-15T00:00:00   \n",
       "10047  https://i.thriftbooks.com/api/imagehandler/m/4...  2013-04-30T00:00:00   \n",
       "10048  https://img.thriftbooks.com/api/images/e/m/43B...  2002-03-07T00:00:00   \n",
       "10049  https://i.thriftbooks.com/api/imagehandler/m/C...  2000-01-01T00:00:00   \n",
       "\n",
       "                      publisher  number_of_pages   price  \\\n",
       "0                       Corsair              303   14.39   \n",
       "1        Arthur A. Levine Books              320    4.29   \n",
       "2                           NaN                0  187.89   \n",
       "3      Grand Central Publishing              288    4.19   \n",
       "4                     HarperOne              197    5.49   \n",
       "...                         ...              ...     ...   \n",
       "10045         Harper Paperbacks              352   10.49   \n",
       "10046                     Delta              160    6.99   \n",
       "10047                  Crossway              208   11.99   \n",
       "10048         Warner Home Video                0    4.19   \n",
       "10049            Veritas Pr Inc              445    6.39   \n",
       "\n",
       "                                authors    rating  number_of_ratings  \\\n",
       "0                           Delia Owens  3.897698                391   \n",
       "1                          J.K. Rowling  3.405858                239   \n",
       "2                         George Orwell  3.695279                233   \n",
       "3                            Harper Lee  3.548387                186   \n",
       "4                          Paulo Coelho  4.002950                339   \n",
       "...                                 ...       ...                ...   \n",
       "10045                      Esther Perel  3.666667                  3   \n",
       "10046  Louise Bates Ames,Frances L. Ilg  5.000000                  5   \n",
       "10047                        John Piper  4.083333                 12   \n",
       "10048                               NaN  2.888889                  9   \n",
       "10049                       Jay L. Wile  4.125000                  8   \n",
       "\n",
       "       number_of_reviews  \n",
       "0                     95  \n",
       "1                     38  \n",
       "2                     24  \n",
       "3                     35  \n",
       "4                     27  \n",
       "...                  ...  \n",
       "10045                  1  \n",
       "10046                  5  \n",
       "10047                  5  \n",
       "10048                  3  \n",
       "10049                  6  \n",
       "\n",
       "[10050 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_book = pd.read_csv('E:/PBL6/ModelAI/data/thrift-preprocessed-summarize-problem.csv')\n",
    "df_book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_book = df_book.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = joblib.load('E:/PBL6/ModelAI/data/TF-IDF/tfidf_matrix_svd4000.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.86646143e-01, -1.14063726e-02, -4.93540994e-03, ...,\n",
       "        7.21566255e-03,  1.54067022e-04,  9.12000073e-03])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['book_id',\t'user_id',\t'age',\t'gender_encoded',\t'area_encoded']]  # features\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 248957, \"Harry Potter and the Sorcerer's Stone\",\n",
       "        'beloved first book harry potter series fully illustrated award winning artist jim kay.for first time j.k. rowling beloved harry potter book presented lavishly illustrated full color editions. award winning artist jim kay created 100 stunning illustration making deluxe format perfect gift child introduced series dedicated fans.harry potter never star quidditch team scoring point riding broom far ground. know spell never helped hatch dragon never worn cloak invisibility.all know miserable life dursleys horrible aunt uncle abominable son dudley great big swollen spoiled bully. harry room tiny closet foot stair birthday party eleven years.but change mysterious letter arrives owl messenger letter invitation incredible place harry anyone read find unforgettable.',\n",
       "        'Paperback',\n",
       "        'https://i.thriftbooks.com/api/imagehandler/m/96FD86FE12A253FA10F44EBA3CC6E56D4FE738B0.jpeg',\n",
       "        '1998-09-01T00:00:00', 'Arthur A. Levine Books', 320, 4.29,\n",
       "        'J.K. Rowling', 3.40585774058577, 239, 38],\n",
       "       [9051, 248957, \"Harry Potter and the Sorcerer's Stone\",\n",
       "        'beloved first book harry potter series fully illustrated award winning artist jim kay.for first time j.k. rowling beloved harry potter book presented lavishly illustrated full color editions. award winning artist jim kay created 100 stunning illustration making deluxe format perfect gift child introduced series dedicated fans.harry potter never star quidditch team scoring point riding broom far ground. know spell never helped hatch dragon never worn cloak invisibility.all know miserable life dursleys horrible aunt uncle abominable son dudley great big swollen spoiled bully. harry room tiny closet foot stair birthday party eleven years.but change mysterious letter arrives owl messenger letter invitation incredible place harry anyone read find unforgettable.',\n",
       "        'Paperback',\n",
       "        'https://i.thriftbooks.com/api/imagehandler/m/96FD86FE12A253FA10F44EBA3CC6E56D4FE738B0.jpeg',\n",
       "        '1998-09-01T00:00:00', 'Arthur A. Levine Books', 320, 4.29,\n",
       "        'J.K. Rowling', 3.40585774058577, 239, 38]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = X.to_numpy()\n",
    "row = df_book[df_book['id'] == 248957]\n",
    "row.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_feature = []\n",
    "# for i in range(len(X_data)):\n",
    "#     book_id = X_data[i][0]\n",
    "#     find_book = (df_book[df_book['id'] == book_id])\n",
    "#     find_book = find_book.to_numpy()\n",
    "#     book_index = find_book[0][0]\n",
    "#     tf_array = tfidf_matrix[book_index]\n",
    "#     # print('tfidf_matrix[book_index]',tf_array.shape)\n",
    "#     # X_data[i] = np.concatenate((X_data[i], tf_array[0]))\n",
    "#     X_i = np.hstack((X_data[i],tf_array))\n",
    "#     X_feature.append(X_i)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save reshaped_array to a file named \"data.joblib\"\n",
    "# dump(X_feature, 'tf_matrix_svd_feature.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data from the \"data.joblib\" file\n",
    "X_feature = load('tf_matrix_svd_feature.pkl')\n",
    "\n",
    "# Now reshaped_array_loaded contains the data loaded from the \"data.joblib\" file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_feature, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4005,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151230    5\n",
       "95076     4\n",
       "41712     1\n",
       "169119    1\n",
       "63282     5\n",
       "         ..\n",
       "119879    4\n",
       "103694    5\n",
       "131932    1\n",
       "146867    1\n",
       "121958    1\n",
       "Name: rating, Length: 160097, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m GB \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# pipeline_gb = Pipeline([\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#     ('tfidf', TfidfVectorizer()),\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#     ('GradientBoostingClassifier', GradientBoostingClassifier())\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# ])\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mGB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m y_predGB \u001b[38;5;241m=\u001b[39m GB\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\ensemble\\_gb.py:586\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\ensemble\\_gb.py:663\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    656\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    657\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    658\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    659\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 663\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\ensemble\\_gb.py:246\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    243\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    245\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 246\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    249\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    250\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    251\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    259\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# GB = GradientBoostingClassifier()\n",
    "# # pipeline_gb = Pipeline([\n",
    "# #     ('tfidf', TfidfVectorizer()),\n",
    "# #     ('GradientBoostingClassifier', GradientBoostingClassifier())\n",
    "# # ])\n",
    "# GB.fit(X_train, y_train)\n",
    "# y_predGB = GB.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Đánh giá mô hình bằng Mean Squared Error (MSE)\n",
    "# mseGB = mean_squared_error(y_test, y_predGB)\n",
    "# print(\"Mean Squared Error:\", mseGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# model = LinearRegression()\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LinearRegression = load('model_LinearRegression.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>area</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>area_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>1263</td>\n",
       "      <td>249355</td>\n",
       "      <td>5635</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>south_asian</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49633</th>\n",
       "      <td>49633</td>\n",
       "      <td>250132</td>\n",
       "      <td>5635</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>south_asian</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62130</th>\n",
       "      <td>62130</td>\n",
       "      <td>249994</td>\n",
       "      <td>5635</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>south_asian</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85449</th>\n",
       "      <td>85449</td>\n",
       "      <td>248592</td>\n",
       "      <td>5635</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>south_asian</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90397</th>\n",
       "      <td>90397</td>\n",
       "      <td>246039</td>\n",
       "      <td>5635</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>south_asian</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181771</th>\n",
       "      <td>181771</td>\n",
       "      <td>14572273</td>\n",
       "      <td>5635</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>south_asian</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating_id   book_id  user_id  rating  age  gender         area  \\\n",
       "1263         1263    249355     5635       5   26  Female  south_asian   \n",
       "49633       49633    250132     5635       5   26  Female  south_asian   \n",
       "62130       62130    249994     5635       5   26  Female  south_asian   \n",
       "85449       85449    248592     5635       5   26  Female  south_asian   \n",
       "90397       90397    246039     5635       2   26  Female  south_asian   \n",
       "181771     181771  14572273     5635       5   26  Female  south_asian   \n",
       "\n",
       "        gender_encoded  area_encoded  \n",
       "1263                 0             9  \n",
       "49633                0             9  \n",
       "62130                0             9  \n",
       "85449                0             9  \n",
       "90397                0             9  \n",
       "181771               0             9  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_userid_3 = df[df['user_id'] == 5635]\n",
    "rows_with_userid_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([246045,   7417,     30,      0,      3], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = X_data[5635][1:]\n",
    "# X_data_modified = X_data[:, 1:]\n",
    "book_id_test = [246045]\n",
    "input = np.concatenate((book_id_test, user))\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LinearRegression.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(model, 'model_LinearRegression.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 2.388487298461521\n",
    "Mean Squared Error: 0.9910420985621311\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Đánh giá mô hình bằng Mean Squared Error (MSE)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors = y_test - y_pred\n",
    "\n",
    "# # Tính toán RMSE\n",
    "# rmse = np.sqrt(np.mean(errors**2))\n",
    "# print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error (RMSE): 0.9955109736020649\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "modelLogisticRegression = LogisticRegression()\n",
    "\n",
    "modelLogisticRegression.fit(X_train, y_train)\n",
    "y_pred = modelLogisticRegression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3.744959400374766\n"
     ]
    }
   ],
   "source": [
    "mseLogisticRegression = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mseLogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autosklearn.classification\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
